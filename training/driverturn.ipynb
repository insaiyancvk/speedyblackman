{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61101808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch, time, warnings, keyboard, time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from PIL import Image\n",
    "from mss import mss\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ffadea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = False\n",
    "d = False\n",
    "\n",
    "transformturn = transforms.Compose([\n",
    "                        transforms.ToTensor(),                    \n",
    "                        transforms.Resize([256,256]),\n",
    "                        transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "384d5cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = ['w','s']\n",
    "w, s = False, False\n",
    "transformacc = transforms.Compose([\n",
    "                    transforms.Resize([256,256]),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "                    ])\n",
    "\n",
    "resnetAcc = torchvision.models.resnet18(pretrained=False)\n",
    "resnetAcc.fc = nn.Linear(resnetAcc.fc.in_features, len(acc))\n",
    "resnetAcc.load_state_dict(torch.load('data\\set1\\SpeedyNet18acc.pth', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a3a143",
   "metadata": {},
   "source": [
    "## ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b480277",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnetTurn = resnet18(pretrained=False)\n",
    "resnetTurn.fc = nn.Linear(resnetTurn.fc.in_features, len(turns))\n",
    "resnetTurn.load_state_dict(torch.load('data\\set2\\SpeedyNet18.pth', map_location=torch.device('cpu')))\n",
    "resnetTurn.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587d72d7",
   "metadata": {},
   "source": [
    "## MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcb10a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelturn = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=False, verbose=False)\n",
    "modelturn.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=False),\n",
    "    nn.Linear(in_features=1280, out_features = 3)\n",
    ")\n",
    "modelturn.load_state_dict(torch.load('data\\set2\\MobileNetV2turnsCroppedimgsNoNorm.pth', map_location=torch.device('cpu')))\n",
    "modelturn.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01c5354",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69db6241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes: int = 3, dropout: float = 0.5) -> None:\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "modelturn = AlexNet()\n",
    "print(modelturn.load_state_dict(torch.load('data\\set2\\AlexNetTurnCroppedimgs.pth', map_location=torch.device('cpu'))))\n",
    "modelturn.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c581e09f",
   "metadata": {},
   "source": [
    "## VGG19 batch normalization - BAD IDEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e42cc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelturn = vgg19_bn(pretrained=False)\n",
    "modelturn.classifier[6] = nn.Linear(in_features=4096, out_features = 3)\n",
    "print(modelturn.load_state_dict(torch.load('data\\set2\\VGG19_bn_crpimg.pth', map_location=torch.device('cpu'))))\n",
    "modelturn.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb397dbf",
   "metadata": {},
   "source": [
    "## Inception V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb789c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelturn = torchvision.models.inception_v3(pretrained=False)\n",
    "modelturn.fc = nn.Linear(in_features=2048, out_features = 3)\n",
    "print(modelturn.load_state_dict(torch.load('data\\set2\\InceptionV3_croppedimgs.pth', map_location=torch.device('cpu'))))\n",
    "modelturn.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418797e0",
   "metadata": {},
   "source": [
    "## DenseNet161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8198798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelturn = torchvision.models.densenet161(pretrained=False, num_classes=3)\n",
    "print(modelturn.load_state_dict(torch.load('data\\set2\\DenseNet161_croppedimgs.pth', map_location=torch.device('cpu'))['weights']))\n",
    "modelturn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "249618ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def screen_record_efficient(top = 300, left = 0, width = 1920, height = 300):\n",
    "  \n",
    "    mon = {\"top\": top, \"left\": left, \"width\": width, \"height\": height}\n",
    "    sct = mss()\n",
    "    img = np.array(sct.grab(mon))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGRA2RGB)\n",
    "    sct.close()\n",
    "    return img\n",
    "\n",
    "def flex(np_img, turnpreds,window_name = \"foo\"):\n",
    "    global a,d\n",
    "    np_img = cv2.cvtColor(np_img, cv2.COLOR_BGR2RGB)\n",
    "    if turnPreds[0]>0.75: # Left\n",
    "        if d:\n",
    "            keyboard.release('d')\n",
    "            d = False\n",
    "        keyboard.press(\"a\")\n",
    "        a = True\n",
    "        np_img = cv2.arrowedLine(np_img, (960, 225), (820, 225),color = (0, 0, 255), thickness= 5, tipLength=.5) \n",
    "        \n",
    "    elif turnPreds[1]>0.5: # Center\n",
    "        if a:\n",
    "            keyboard.release('a')\n",
    "            a = False\n",
    "        elif d:\n",
    "            keyboard.release('d')\n",
    "            d = False\n",
    "        np_img = cv2.arrowedLine(np_img, (960, 225), (960, 85),color = (0, 0, 255), thickness= 5, tipLength=.5) \n",
    "        \n",
    "    elif turnPreds[2]>0.75: # Right\n",
    "        if a:\n",
    "            keyboard.release('a')\n",
    "            a = False\n",
    "        keyboard.press(\"d\")\n",
    "        d = True\n",
    "        np_img = cv2.arrowedLine(np_img, (960, 225), (1100, 225),color = (0, 0, 255), thickness= 5, tipLength=.5)\n",
    "    \n",
    "    cv2.imshow(window_name, np_img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7709cbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    t = True\n",
    "    \n",
    "    while t:\n",
    "        \n",
    "        try:\n",
    "            foo = screen_record_efficient()\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                cv2.destroyAllWindows()\n",
    "                break\n",
    "            \n",
    "            transformed_foo = transform(foo)\n",
    "            transformed_foo = transformed_foo.unsqueeze(0)\n",
    "            turnPreds = nn.functional.softmax(modelturn(transformed_foo)[0], dim=0)\n",
    "            turnPreds = turnPreds.detach().numpy()\n",
    "            flex(foo, turnpreds = turnPreds,window_name='speedyblackmanCAM')\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "\n",
    "            print(\"Pausing the code\")\n",
    "            t = input(\"Paused\")\n",
    "            if t == \"q\":\n",
    "                t == False\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b871e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "!code ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
